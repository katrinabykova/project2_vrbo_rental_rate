{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import chromedriver_binary\n",
    "import pickle\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect urls for pages with property listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urls for Airbnb searches for Seattle\n",
    "\n",
    "'''Urls 1-6 are from multiple searches for \"Seattle\" as location. One search yields ~300 properties. \n",
    "   Subsequent searches give duplicate urls. To inclrease the number of not duplicate urls used keyword \n",
    "   search for links 7-14. E.g. link#10 - propoerties that have 2 or more beadrooms.\n",
    "   \n",
    "'''\n",
    "seattle1 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?adults=1&children=0&checkin=&checkout=&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A1ce0219a-a643-4c55-a468-ec29a0069782%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&refinement_paths%5B%5D=%2Fhomes'\n",
    "seattle2 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?adults=1&children=0&checkin=&checkout=&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A1ce0219a-a643-4c55-a468-ec29a0069782%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&refinement_paths%5B%5D=%2Fhomes'\n",
    "seattle3 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?adults=1&children=0&checkin=&checkout=&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A1ce0219a-a643-4c55-a468-ec29a0069782%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&refinement_paths%5B%5D=%2Fhomes'\n",
    "seattle4 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?adults=1&children=0&checkin=&checkout=&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A63ffe2ee-477d-4903-9f71-e40b3fad5481%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&refinement_paths%5B%5D=%2Fhomes'\n",
    "seattle5 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?adults=1&children=0&checkin=&checkout=&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A63ffe2ee-477d-4903-9f71-e40b3fad5481%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&refinement_paths%5B%5D=%2Fhomes'\n",
    "seattle6 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?refinement_paths%5B%5D=%2Fhomes&current_tab_id=home_tab&selected_tab_id=home_tab&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A63ffe2ee-477d-4903-9f71-e40b3fad5481%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&place_id=ChIJVTPokywQkFQRmtVEaUZlJRA&s_tag=tLFHWR38&search_type=pagination&screen_size=large&hide_dates_and_guests_filters=false&adults=1&last_search_session_id=d7f2e161-cce8-44a1-86d6-b59bce0f84ea'\n",
    "# pets\n",
    "seattle7 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?refinement_paths%5B%5D=%2Fhomes&current_tab_id=home_tab&selected_tab_id=home_tab&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A63ffe2ee-477d-4903-9f71-e40b3fad5481%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&place_id=ChIJVTPokywQkFQRmtVEaUZlJRA&search_type=filter_change&screen_size=large&hide_dates_and_guests_filters=false&adults=1&amenities%5B%5D=12'\n",
    "# smoking\n",
    "seattle8 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?refinement_paths%5B%5D=%2Fhomes&current_tab_id=home_tab&selected_tab_id=home_tab&place_id=ChIJVTPokywQkFQRmtVEaUZlJRA&search_type=filter_change&screen_size=large&hide_dates_and_guests_filters=false&amenities%5B%5D=11'\n",
    "# 2 beds\n",
    "seattle9 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?refinement_paths%5B%5D=%2Fhomes&current_tab_id=home_tab&selected_tab_id=home_tab&place_id=ChIJVTPokywQkFQRmtVEaUZlJRA&search_type=filter_change&screen_size=large&hide_dates_and_guests_filters=false&min_beds=2'\n",
    "# 2 bedrooms\n",
    "seattle10 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?refinement_paths%5B%5D=%2Fhomes&current_tab_id=home_tab&selected_tab_id=home_tab&place_id=ChIJVTPokywQkFQRmtVEaUZlJRA&search_type=filter_change&screen_size=large&hide_dates_and_guests_filters=false&min_beds=0&min_bedrooms=2'\n",
    "# kitchen\n",
    "seattle11 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A1ce0219a-a643-4c55-a468-ec29a0069782%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&refinement_paths%5B%5D=%2Fhomes&adults=1&place_id=ChIJVTPokywQkFQRmtVEaUZlJRA&amenities%5B%5D=8&search_type=filter_change'\n",
    "# 3 bedrooms\n",
    "seattle12 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?refinement_paths%5B%5D=%2Fhomes&current_tab_id=home_tab&selected_tab_id=home_tab&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A1ce0219a-a643-4c55-a468-ec29a0069782%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&adults=1&place_id=ChIJVTPokywQkFQRmtVEaUZlJRA&search_type=filter_change&screen_size=large&hide_dates_and_guests_filters=false&min_bedrooms=3'\n",
    "#  3 beds\n",
    "seattle13 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?refinement_paths%5B%5D=%2Fhomes&current_tab_id=home_tab&selected_tab_id=home_tab&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A1ce0219a-a643-4c55-a468-ec29a0069782%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&adults=1&place_id=ChIJVTPokywQkFQRmtVEaUZlJRA&search_type=filter_change&screen_size=large&hide_dates_and_guests_filters=false&min_bedrooms=0&min_bathrooms=0&min_beds=3'\n",
    "# property type - house\n",
    "seattle14 = 'https://www.airbnb.com/s/Seattle--WA--United-States/homes?refinement_paths%5B%5D=%2Fhomes&current_tab_id=home_tab&selected_tab_id=home_tab&source=mc_search_bar&click_referer=t%3ASEE_ALL%7Csid%3A1ce0219a-a643-4c55-a468-ec29a0069782%7Cst%3ALANDING_PAGE_MARQUEE&title_type=NONE&place_id=ChIJVTPokywQkFQRmtVEaUZlJRA&search_type=filter_change&screen_size=large&hide_dates_and_guests_filters=false&adults=1&min_beds=0&property_type_id%5B%5D=2'\n",
    "\n",
    "location_urls_1 = [\n",
    "    seattle1, seattle2, seattle3, seattle4, seattle5,\n",
    "    seattle6, seattle7, seattle8, seattle9, seattle10\n",
    "]\n",
    "\n",
    "location_urls_2 = [\n",
    "    seattle11, seattle12, seattle13, seattle14\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_list2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-357-9468e9b49832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdict_list_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_prop_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation_urls_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_list2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_list2' is not defined"
     ]
    }
   ],
   "source": [
    "# Collecting property listings.\n",
    "dict_list_1 = collect_prop_urls(location_urls_1)\n",
    "dict_list_2 = collect_prop_urls(location_urls_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle page urls\n",
    "with open('dict_list_1.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_list_1, f)\n",
    "    \n",
    "with open('dict_list_2.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_list_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "247\n",
      "255\n",
      "257\n"
     ]
    }
   ],
   "source": [
    "# Number of urls collected for each link for dict_list_1\n",
    "for dict in dict_list_1:\n",
    "    print(len(dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of urls collected for each link for dict_list_2\n",
    "for dict in dict_list_2:\n",
    "    print(len(dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_all = dict_list_1 + dict_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate urls\n",
    "dict_list_un_all = unique_prop_urls(dict_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n",
      "122\n",
      "22\n",
      "43\n",
      "29\n",
      "9\n",
      "216\n",
      "157\n",
      "134\n",
      "182\n",
      "40\n",
      "184\n",
      "92\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Number of urls collected for each link for dict_list_un_all\n",
    "for dict in dict_list_un_all:\n",
    "    print(len(dict))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle page urls\n",
    "with open('dict_lits_un_all.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_lits_un_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "\n",
    "def collect_prop_urls(url_list):\n",
    "    dict_list = []\n",
    "    for url in url_list:\n",
    "        page_urls = collect_page_urls(url)\n",
    "        element_urls = collect_objct_urls(page_urls)\n",
    "        prop_urls = select_prop_urls(element_urls)\n",
    "        prop_urls_dict = make_dict_prop_id_url(prop_urls)\n",
    "        \n",
    "      # check for unique properties\n",
    "#         prop_urls_dict_un = set(prop_urls_dict)\n",
    "        dict_list.append(prop_urls_dict)\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "\n",
    "def unique_prop_urls(url_dict_list):\n",
    "    url_dict_list_un = []\n",
    "    url_dict_list_un.append(url_dict_list[0])\n",
    "    preceding_dicts = url_dict_list[0].copy() \n",
    "    \n",
    "    for dict in url_dict_list[1:]:\n",
    "        url_dict_un = check_dict(dict, preceding_dicts)\n",
    "        \n",
    "        preceding_dicts.update(url_dict_un)\n",
    "        \n",
    "        url_dict_list_un.append(url_dict_un)\n",
    "        \n",
    "    return url_dict_list_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "\n",
    "def check_dict(dict1, dict2):\n",
    "    dict_w_unique_properties = {}\n",
    "    for key, val in dict1.items():\n",
    "        if key not in dict2:\n",
    "            dict_w_unique_properties[key] = val\n",
    "    return dict_w_unique_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Collect a list of page urls \n",
    "\n",
    "def collect_page_urls(start_url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(start_url)\n",
    "\n",
    "# add starting page 1 url\n",
    "    page_urls_list = []\n",
    "    page_urls_list.append(driver.current_url)\n",
    "    time.sleep(7)\n",
    "\n",
    "# move to page 2\n",
    "    next_page = driver.find_elements_by_class_name(\"_1m76pmy\")[0]\n",
    "    next_page.click()\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "# collect urls and move to subsequent pages\n",
    "    while True:\n",
    "        page_url = driver.current_url\n",
    "        page_urls_list.append(page_url)\n",
    "        try:\n",
    "            next_page = driver.find_elements_by_class_name(\"_1m76pmy\")[1]\n",
    "        except IndexError:\n",
    "            break\n",
    "        next_page.click()\n",
    "        time.sleep(7)\n",
    "    \n",
    "    return page_urls_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect urls for property listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Collect urls from webpages for each location\n",
    "\n",
    "def collect_objct_urls(page_urls_list):      \n",
    "    link_list = []\n",
    "    for url in page_urls_list:     \n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        link_elements = driver.find_elements_by_tag_name('a')\n",
    "        for element in link_elements:\n",
    "            try:                                                 # handling stale element error\n",
    "                link = element.get_attribute('href')\n",
    "                link_list.append(link)\n",
    "            except StaleElementReferenceException:\n",
    "                pass\n",
    "        driver.close()\n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1636"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make combined dict with all urls\n",
    "dict_combined = {k:v for d in dict_list_un_all for k, v in d.items() }\n",
    "# for k, v in [x.items() for x in lst]:\n",
    "len(dict_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Select property urls\n",
    "\n",
    "def select_prop_urls(url_list):\n",
    "            \n",
    "# make sure all links are str type\n",
    "    link_list_str = []\n",
    "    for element in url_list:\n",
    "        if type(element)==str:\n",
    "            link_list_str.append(element)\n",
    "        \n",
    "# sort for property urls \n",
    "    property_urls = []\n",
    "    text = 'name=1000'\n",
    "    for url in link_list_str:\n",
    "        if url.find(text) >=0:\n",
    "            property_urls.append(url)                     \n",
    "        \n",
    "# remove duplicates       \n",
    "    property_urls = set(property_urls)\n",
    "    return property_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_prop_urls3 = select_prop_urls(seattle_obsr_urls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: extract property ID from url\n",
    "\n",
    "def url_to_id(url):\n",
    "    to_num = lambda num: int(''.join(i for i in num)) \n",
    "    prop_id = to_num(re.findall(r'\\d', url.split('?')[0]))\n",
    "    return prop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Make dict with urls and property IDs\n",
    "\n",
    "def make_dict_prop_id_url(url_list):\n",
    "    dict_id_url = {}\n",
    "    for url in url_list:\n",
    "        dict_id_url[url_to_id(url)] = url\n",
    "    return dict_id_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict with url IDs and urls\n",
    "# seattle_prop_urls_dict = make_dict_prop_id_url(seattle_prop_urls)\n",
    "# shoreline_prop_urls_dict = make_dict_prop_id_url(shoreline_prop_urls)\n",
    "# bellevue_prop_urls_dict = make_dict_prop_id_url(bellevue_prop_urls)\n",
    "# redmond_prop_urls_dict = make_dict_prop_id_url(redmond_prop_urls)\n",
    "# seattle_prop_urls_dict2 = make_dict_prop_id_url(seattle_prop_urls2)\n",
    "seattle_prop_urls_dict3 = make_dict_prop_id_url(seattle_prop_urls3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: make a dict with not repeating entries as compared to another dict\n",
    "\n",
    "def check_dict(dict1, dict2):\n",
    "    dict_w_unique_properties = {}\n",
    "    for key, val in dict1.items():\n",
    "        if key not in dict2:\n",
    "            dict_w_unique_properties[key] = val\n",
    "    return dict_w_unique_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle prop_urls\n",
    "with open('dict_combined.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_combined, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['property_id', 'price', 'guests', 'bedrooms', 'beds', \n",
    "        'baths', 'latitude', 'longitude', 'review_rate', 'review_num', \n",
    "        'property_type', 'link']\n",
    "df_raw = pd.DataFrame(columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use selenium to extract raw features from a single web page\n",
    "def get_raw_feature_row(prop_id, url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(7) \n",
    "    \n",
    "# set raw features to nan\n",
    "    property_id, price, guests, bedrooms, beds, baths, property_type, review_rate, review_num, link, latitude, longitude = [np.nan]*12\n",
    "    \n",
    "    property_id = prop_id\n",
    "    link = driver.current_url\n",
    "    \n",
    "# get raw features\n",
    "    try:\n",
    "        price = int(driver.find_element_by_class_name('_doc79r').text[1:])\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        guests = int(driver.find_elements_by_class_name('_czm8crp')[1].text.split()[0])\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        bedrooms = str(driver.find_elements_by_class_name('_czm8crp')[2].text.split()[0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        beds = int(driver.find_elements_by_class_name('_czm8crp')[3].text.split()[0])\n",
    "    except:\n",
    "        pass    \n",
    "    \n",
    "    try:\n",
    "        baths = float(driver.find_elements_by_class_name('_czm8crp')[4].text.split()[0])\n",
    "    except:\n",
    "        pass   \n",
    "    \n",
    "    try:\n",
    "        property_type = str(driver.find_elements_by_class_name('_1p3joamp')[0].text)\n",
    "    except: \n",
    "        pass    \n",
    "    \n",
    "    try:\n",
    "        location = driver.find_element_by_xpath('//*[@id=\"neighborhood\"]/div/div/div/div/div/section/div[2]/div[2]/div[1]').get_attribute('innerHTML')\n",
    "        \n",
    "        loc_str = re.search('(?<=maps/@).*(?=/data=)', location)[0]\n",
    "\n",
    "        latitude = float(loc_str.split(',')[0])\n",
    "        longitude = float(loc_str.split(',')[1])\n",
    "    except: \n",
    "        pass   \n",
    "    \n",
    "    try:\n",
    "        review_rate = float(driver.find_element_by_class_name('_tghtxy2').text)\n",
    "    except:\n",
    "#     except erorrs as er: \n",
    "        pass \n",
    "\n",
    "    \n",
    "    try:\n",
    "        to_num = lambda num: int(''.join(i for i in num)) \n",
    "        review_num = to_num(re.findall(r'\\d', driver.find_element_by_class_name('_1plk0jz1').text))\n",
    "#         review_num = to_num(re.findall(r'\\d', driver.find_elements_by_class_name('_krjbj')[4].text))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# add data in a row fashion to a dataframe\n",
    "    row = {\n",
    "        'property_id': property_id,\n",
    "        'price': price, \n",
    "        'guests':guests, \n",
    "        'bedrooms':bedrooms, \n",
    "        'beds':beds, \n",
    "        'baths':baths,  \n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'review_rate':review_rate, \n",
    "        'review_num':review_num, \n",
    "        'property_type':property_type,\n",
    "        'link': link\n",
    "    }\n",
    "    driver.close()\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['property_id', 'price', 'guests', 'bedrooms', 'beds', \n",
    "        'baths', 'latitude', 'longitude', 'review_rate', 'review_num', \n",
    "        'property_type', 'link']\n",
    "\n",
    "df_raw = pd.DataFrame(columns = cols)\n",
    "\n",
    "for prop_id, url in dict_combined.items():\n",
    "    row = get_raw_feature_row(prop_id, url)\n",
    "    df_raw = df_raw.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1636 entries, 0 to 1635\n",
      "Data columns (total 12 columns):\n",
      "property_id      1636 non-null object\n",
      "price            1519 non-null float64\n",
      "guests           1506 non-null float64\n",
      "bedrooms         1634 non-null object\n",
      "beds             1525 non-null float64\n",
      "baths            1514 non-null float64\n",
      "latitude         1525 non-null float64\n",
      "longitude        1525 non-null float64\n",
      "review_rate      1491 non-null float64\n",
      "review_num       1383 non-null float64\n",
      "property_type    1634 non-null object\n",
      "link             1636 non-null object\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 153.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle df_raw\n",
    "with open('df_raw.pkl', 'wb') as f:\n",
    "    pickle.dump(df_raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1636 entries, 0 to 1635\n",
      "Data columns (total 12 columns):\n",
      "property_id      1636 non-null object\n",
      "price            1519 non-null float64\n",
      "guests           1506 non-null float64\n",
      "bedrooms         1634 non-null object\n",
      "beds             1525 non-null float64\n",
      "baths            1514 non-null float64\n",
      "latitude         1525 non-null float64\n",
      "longitude        1525 non-null float64\n",
      "review_rate      1491 non-null float64\n",
      "review_num       1383 non-null float64\n",
      "property_type    1634 non-null object\n",
      "link             1636 non-null object\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 153.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "property_type    Entire home\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.info()\n",
    "df_raw['property_id'].value_counts()\n",
    "len(df_raw['property_id'].unique())\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect raw data for seattle location\n",
    "for url in seattle_prop_urls:\n",
    "    row = get_raw_feature_row(url)\n",
    "    df_seattle = df_seattle.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle df_raw\n",
    "with open('df_seattle.pkl', 'wb') as f:\n",
    "    pickle.dump(df_seattle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect raw data for shoreline location\n",
    "cols = ['link', 'price', 'guests', 'bedrooms', 'beds', 'baths', \n",
    "        'review_rate', 'review_num', 'property_type']\n",
    "df_shoreline = pd.DataFrame(columns = cols)\n",
    "\n",
    "# collect raw data\n",
    "for url in shoreline_prop_urls_un:\n",
    "    row = get_raw_feature_row(url)\n",
    "    df_shoreline = df_shoreline.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle df_bellevue\n",
    "with open('df_shoreline.pkl', 'wb') as f:\n",
    "    pickle.dump(df_shoreline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect raw data for bellevue location\n",
    "cols = ['link', 'price', 'guests', 'bedrooms', 'beds', 'baths', \n",
    "        'review_rate', 'review_num', 'property_type']\n",
    "df_bellevue = pd.DataFrame(columns = cols)\n",
    "\n",
    "# collect raw data\n",
    "for url in bellevue_prop_urls_un:\n",
    "    row = get_raw_feature_row(url)\n",
    "    df_bellevue = df_bellevue.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle df_bellevue\n",
    "with open('df_bellevue.pkl', 'wb') as f:\n",
    "    pickle.dump(df_bellevue, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect raw data for bellevue location\n",
    "cols = ['link', 'price', 'guests', 'bedrooms', 'beds', 'baths', \n",
    "        'review_rate', 'review_num', 'property_type']\n",
    "df_redmond = pd.DataFrame(columns = cols)\n",
    "\n",
    "# collect raw data\n",
    "for url in redmond_prop_urls_un:\n",
    "    row = get_raw_feature_row(url)\n",
    "    df_redmond = df_redmond.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle df_redmond\n",
    "with open('df_redmond.pkl', 'wb') as f:\n",
    "    pickle.dump(df_redmond, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect raw data for bellevue location\n",
    "cols = ['link', 'price', 'guests', 'bedrooms', 'beds', 'baths', \n",
    "        'review_rate', 'review_num', 'property_type']\n",
    "df_seattle2 = pd.DataFrame(columns = cols)\n",
    "\n",
    "# collect raw data\n",
    "for url in redmond_prop_urls_un:\n",
    "    row = get_raw_feature_row(url)\n",
    "    df_seattle2 = df_seattle2.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle df_redmond\n",
    "with open('df_seattle2.pkl', 'wb') as f:\n",
    "    pickle.dump(df_seattle2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.concat([df_seattle, df_seattle2, df_shoreline, df_bellevue, df_redmond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(868, 9)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: float}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x:type(x) for x in df_seattle2.price.unique() if not type(x) == int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = list(seattle_prop_urls)[37]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "time.sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = list(seattle_prop_urls)[36]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "time.sleep(30) \n",
    "\n",
    "# coordinates = driver.find_elements_by_class_name('_e296pg')\n",
    "\n",
    "\n",
    "\n",
    "src = driver.find_element_by_xpath('//*[@id=\"neighborhood\"]/div/div/div/div/div/section/div[2]/div[2]/div[2]/img').get_attribute(\"src\")\n",
    "src.location_once_scrolled_into_view\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect raw data\n",
    "for url in seattle_prop_urls:\n",
    "    row = get_raw_feature_row(url)\n",
    "    df_raw = df_raw.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle df_raw\n",
    "with open('df_raw.pkl', 'wb') as f:\n",
    "    pickle.dump(df_raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
